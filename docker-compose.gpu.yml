# GPU override for NLLB service.
# Usage:
#   docker compose -f docker-compose.yml -f docker-compose.gpu.yml up -d --build
# Notes:
# - Requires NVIDIA drivers + NVIDIA Container Toolkit (Linux) or Docker Desktop GPU (WSL2) on Windows.
# - Compose will pass GPU devices into the nllb container via `gpus: all`.

services:
  nllb:
    # Reuse the existing image/build/volumes/ports from docker-compose.yml
    # Add GPU access + a few safe CUDA/PyTorch env tweaks.
    gpus: all
    environment:
      # Make all GPUs visible inside the container (toolkit honors this).
      - NVIDIA_VISIBLE_DEVICES=all
      # Optional PyTorch allocator hint to reduce fragmentation on large models.
      - TORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
    # Give a bit more shared memory for larger batches/tokenizers (optional).
    shm_size: "2g"
